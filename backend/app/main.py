from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from app.models import NewsInput, MediaPlan, NewsAnalysis, RegenerateRequest, GeneratedPost, Platform, BrandProfile
from app.agents.graph import app as agent_app
import uuid

from app.database import engine, Base
from app.auth.router import router as auth_router, get_current_user
from app.auth.models import User
from fastapi import Depends

# Create Tables
Base.metadata.create_all(bind=engine)

app = FastAPI()

app.include_router(auth_router)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def read_root():
    return {"Hello": "World", "Service": "AI-Newsmaker Backend"}

@app.get("/history")
async def get_history(user: User = Depends(get_current_user)):
    """Returns recent generations from MinIO for the current user."""
    from app.storage import storage
    return storage.list_generations(user_id=user.id, limit=12)

@app.get("/history/{plan_id}")
async def get_plan(plan_id: str, user: User = Depends(get_current_user)):
    """Returns a specific plan by ID for the current user."""
    from app.storage import storage
    data = storage.get_generation(user_id=user.id, plan_id=plan_id)
    if not data:
        raise HTTPException(status_code=404, detail="–ü–ª–∞–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")
    return data

@app.post("/generate", response_model=MediaPlan)
async def generate_plan(news: NewsInput, user: User = Depends(get_current_user)):
    """
    Triggers the AI Agent workflow to generate a media plan.
    """
    try:
        # Run the LangGraph workflow with user context and mode
        initial_state = {
            "input": news, 
            "user_id": user.id, 
            "mode": news.mode or "pr",
            "target_brand": news.target_brand,
            "errors": []
        }
        result = await agent_app.ainvoke(initial_state)
        
        if result.get("errors"):
            print(f"Workflow Errors: {result['errors']}")
            raise HTTPException(status_code=500, detail=f"Agent Error: {result['errors']}")
            
        # Construct response
        # Use result['input'] to get the updated news object (with scraped text)
        final_input = result.get("input", news)
        
        plan = MediaPlan(
            id=str(uuid.uuid4()),
            original_news=final_input,
            analysis=result["analysis"],
            posts=result["posts"]
        )
        
        # Save to MinIO History (User specific)
        from app.storage import storage
        storage.save_generation(user.id, plan.id, plan.dict())
        
        return plan
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/regenerate", response_model=GeneratedPost)
async def regenerate_post(request: RegenerateRequest, user: User = Depends(get_current_user)):
    """
    Regenerates a single post for a specific platform.
    """
    from app.agents.writer import get_llm
    from langchain_core.messages import SystemMessage, HumanMessage
    from app.models import GeneratedPost
    import urllib.parse

    try:
        llm = get_llm()
        
        # Reconstruct context (simplified for single post)
        brand_name = request.original_news.brand_profile.name if request.original_news.brand_profile else "Brand"
        
        # Determine style guide and structure based on platform
        if request.platform == Platform.EMAIL:
            style_guide = """
            –§–û–†–ú–ê–¢ –°–õ–£–ñ–ï–ë–ù–û–ô –ó–ê–ü–ò–°–ö–ò.
            –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
            –¢–µ–º–∞: [–ß–µ—Ç–∫–∞—è, –ø–æ–±—É–∂–¥–∞—é—â–∞—è –∫ –¥–µ–π—Å—Ç–≤–∏—é —Ç–µ–º–∞]
            –ö–æ–º—É: [–¶–µ–ª–µ–≤—ã–µ —Å—Ç–µ–π–∫—Ö–æ–ª–¥–µ—Ä—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä, –ú–∞—Ä–∫–µ—Ç–∏–Ω–≥, CEO]
            –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: [–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–æ–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞]
            
            –¢–µ–∫—Å—Ç:
            [–ö—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–∏—Ç—É–∞—Ü–∏–∏ –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏. –û—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ, –Ω–æ –ø—Ä—è–º–æ.]
            """
        elif request.platform == Platform.PRESS_RELEASE:
            style_guide = """
            –§–û–†–ú–ê–¢ –û–§–ò–¶–ò–ê–õ–¨–ù–û–ì–û –ü–†–ï–°–°-–†–ï–õ–ò–ó–ê.
            –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
            –î–õ–Ø –ù–ï–ú–ï–î–õ–ï–ù–ù–û–ì–û –†–ê–°–ü–†–û–°–¢–†–ê–ù–ï–ù–ò–Ø
            
            [–ó–ê–ì–û–õ–û–í–û–ö: –ü—Ä–æ–ø–∏—Å–Ω—ã–º–∏, –í–ø–µ—á–∞—Ç–ª—è—é—â–∏–π]
            
            [–ì–æ—Ä–æ–¥, –î–∞—Ç–∞] ‚Äî [–õ–∏–¥-–∞–±–∑–∞—Ü: –ö—Ç–æ, —á—Ç–æ, –∫–æ–≥–¥–∞, –≥–¥–µ, –ø–æ—á–µ–º—É]
            
            [–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç: –î–µ—Ç–∞–ª–∏, –∫–æ–Ω—Ç–µ–∫—Å—Ç, –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã]
            
            [–û –∫–æ–º–ø–∞–Ω–∏–∏ (—Å–ø—Ä–∞–≤–∫–∞)]
            
            –ö–æ–Ω—Ç–∞–∫—Ç—ã –¥–ª—è –°–ú–ò:
            [–ò–º—è/Email]
            """
            style_guide = """
            Telegram Channel Style.
            - Use Markdown (*bold*, _italic_) for emphasis.
            - Use Emojis üöÄ.
            - Short paragraphs.
            - Call to Action (CTA) at the end.
            """
        elif request.platform == Platform.IMAGE:
             # Logic for Image Regeneration
             prompt = f"""
             YOU ARE AN AI ART DIRECTOR.
             TASK: Create a NEW, BETTER stable diffusion prompt for an image representing this news.
             
             News Analysis:
             {request.analysis.summary}
             
             Visual Analysis:
             Topics: {request.analysis.topics}
             Sentiment: {request.analysis.sentiment}
             
             REQUIREMENTS:
             - English ONLY.
             - Descriptive, visual, artistic.
             - No text in image.
             - Modern, premium, cinematic lighting.
             
             OUTPUT: Just the prompt string.
             """
             
             response = await llm.ainvoke([HumanMessage(content=prompt)])
             image_prompt = response.content.strip()
             
             encoded_prompt = urllib.parse.quote(image_prompt)
             image_url = f"https://image.pollinations.ai/prompt/{encoded_prompt}?nologo=true"
             
             return GeneratedPost(
                platform=Platform.IMAGE,
                content="Image Updated",
                image_prompt=image_prompt,
                image_url=image_url,
                status="draft"
             )
             
        else:
            style_guide = "Engaging social media style. Emojis allowed. NO Markdown headers (like ##). Ready to publish."

        prompt = f"""
        YOU ARE THE OFFICIAL VOICE OF THE BRAND: {brand_name}.
        
        TASK: Rewrite the content for {request.platform.upper()} in RUSSIAN.
        
        Analysis:
        - Summary: {request.analysis.summary}
        - Facts: {", ".join(request.analysis.facts)}
        - Sentiment: {request.analysis.sentiment}
        - PR Verdict: {request.analysis.pr_verdict}
        
        Style Guide: 
        {style_guide}
        
        CRITICAL RULES:
        1. Write AS {brand_name}.
        2. Language: RUSSIAN.
        3. Follow the specific structure for {request.platform.value} defined above.
        
        At the very end, strictly separated by "|||", provide a NEW Image Prompt in English.
        """
        
        messages = [
            SystemMessage(content=f"You are the Head of Communications for {brand_name}."),
            HumanMessage(content=prompt)
        ]
        
        response = await llm.ainvoke(messages)
        
        # Parse
        full_content = response.content
        content = full_content
        image_prompt = "Abstract modern technology"
        
        if "|||" in full_content:
            parts = full_content.split("|||")
            content = parts[0].strip()
            if len(parts) > 1:
                image_prompt = parts[1].strip()
                
        # Generate Image URL
        encoded_prompt = urllib.parse.quote(image_prompt)
        image_url = f"https://image.pollinations.ai/prompt/{encoded_prompt}?nologo=true"
        
        return GeneratedPost(
            platform=request.platform,
            content=content,
            image_prompt=image_prompt,
            image_url=image_url,
            status="draft"
        )
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/monitor/scan", response_model=list[NewsInput])
async def scan_news(target_brand: str | None = None, user: User = Depends(get_current_user)):
    """
    Scans for recent news about a brand.
    - PR mode: uses user's saved brand profile
    - Blogger mode: uses target_brand parameter
    """
    from app.agents.monitoring import search_brand_mentions
    from app.models import BrandProfile
    
    if target_brand:
        # Blogger mode: create temporary profile with just the name
        profile = BrandProfile(
            name=target_brand,
            description="",
            tone_of_voice="",
            target_audience="",
            keywords=[target_brand]
        )
    elif user.brand_profile:
        # PR mode: use user's saved profile
        profile = BrandProfile(**user.brand_profile)
    else:
        raise HTTPException(status_code=400, detail="–£–∫–∞–∂–∏—Ç–µ –±—Ä–µ–Ω–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—Ä–æ—Ñ–∏–ª—å!")
    
    try:
        results = await search_brand_mentions(profile)
        return results
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/feedback")
async def feedback(plan_id: str, like: bool, user: User = Depends(get_current_user)):
    """
    Handles user feedback. If like=True, promotes the case to RAG knowledge base.
    """
    if not like:
        return {"status": "ignored"}
        
    try:
        from app.storage import storage
        from app.rag.store import rag_store
        
        # 1. Get Data first to know the category
        data = storage.get_generation(user.id, plan_id)
        if not data:
             raise HTTPException(status_code=404, detail="Plan not found in history")

        # Extract category (default to ROUTINE if missing, e.g. old plans)
        category = data['analysis'].get('category', 'ROUTINE')
        
        # 2. Promote in MinIO (Copy from history to rag-knowledge/{category})
        success = storage.promote_to_rag(user.id, plan_id, category)
        if not success:
            raise HTTPException(status_code=500, detail="Failed to promote in Storage")
            
        # 3. Index in ChromaDB
        # Create a rich context string
        # Format: "News: ... \n Verdict: ... \n Post: ..."
        # We index the SUMMARY primarily so we can find similar news later.
        # Using Summary ensures language consistency (Russian) and noise reduction.
        news_text = data['analysis']['summary']
        
        verdict = data['analysis']['pr_verdict']
        
        # Metadata allows us to filter or retrieve details
        metadata = {
            "plan_id": plan_id,
            "verdict": verdict,
            "category": category,
            "bucket": "rag-knowledge",
            "user_id": user.id
        }
        
        rag_store.add_case(
            doc_id=plan_id,
            text=news_text,
            metadata=metadata
        )
            
        return {"status": "promoted"}
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))
